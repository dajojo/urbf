{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7321c313e2964e9698555ed984dce8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExperimentDataLoaderWidget(children=(Box(children=(Button(description='Update Descriptions', layout=Layout(hei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "# import the experiment utilities package\n",
    "import exputils as eu\n",
    "import numpy as np\n",
    "\n",
    "# create an experiment data loader, by default it will load data from '../experiments'\n",
    "experiment_data_loader = eu.gui.jupyter.ExperimentDataLoaderWidget()\n",
    "\n",
    "display(experiment_data_loader)\n",
    "experiment_data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Data Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1027_ESL',\n",
       " '1028_SWD',\n",
       " '1029_LEV',\n",
       " '1030_ERA',\n",
       " '1096_FacultySalaries',\n",
       " '1193_BNG_lowbwt',\n",
       " '1196_BNG_pharynx',\n",
       " '1199_BNG_echoMonths',\n",
       " '1201_BNG_breastTumor',\n",
       " '1203_BNG_pwLinear',\n",
       " '1595_poker',\n",
       " '192_vineyard',\n",
       " '210_cloud',\n",
       " '215_2dplanes',\n",
       " '218_house_8L',\n",
       " '225_puma8NH',\n",
       " '228_elusage',\n",
       " '229_pwLinear',\n",
       " '230_machine_cpu',\n",
       " '344_mv',\n",
       " '485_analcatdata_vehicle',\n",
       " '519_vinnie',\n",
       " '522_pm10',\n",
       " '523_analcatdata_neavote',\n",
       " '529_pollen',\n",
       " '537_houses',\n",
       " '547_no2',\n",
       " '556_analcatdata_apnea2',\n",
       " '557_analcatdata_apnea1',\n",
       " '561_cpu',\n",
       " '564_fried',\n",
       " '579_fri_c0_250_5',\n",
       " '591_fri_c1_100_10',\n",
       " '593_fri_c1_1000_10',\n",
       " '594_fri_c2_100_5',\n",
       " '595_fri_c0_1000_10',\n",
       " '596_fri_c2_250_5',\n",
       " '597_fri_c2_500_5',\n",
       " '599_fri_c2_1000_5',\n",
       " '601_fri_c1_250_5',\n",
       " '602_fri_c3_250_10',\n",
       " '604_fri_c4_500_10',\n",
       " '606_fri_c2_1000_10',\n",
       " '608_fri_c3_1000_10',\n",
       " '609_fri_c0_1000_5',\n",
       " '611_fri_c3_100_5',\n",
       " '612_fri_c1_1000_5',\n",
       " '613_fri_c3_250_5',\n",
       " '615_fri_c4_250_10',\n",
       " '617_fri_c3_500_5',\n",
       " '621_fri_c0_100_10',\n",
       " '623_fri_c4_1000_10',\n",
       " '624_fri_c0_100_5',\n",
       " '627_fri_c2_500_10',\n",
       " '628_fri_c3_1000_5',\n",
       " '631_fri_c1_500_5',\n",
       " '634_fri_c2_100_10',\n",
       " '635_fri_c0_250_10',\n",
       " '641_fri_c1_500_10',\n",
       " '646_fri_c3_500_10',\n",
       " '647_fri_c1_250_10',\n",
       " '649_fri_c0_500_5',\n",
       " '654_fri_c0_500_10',\n",
       " '656_fri_c1_100_5',\n",
       " '657_fri_c2_250_10',\n",
       " '659_sleuth_ex1714',\n",
       " '663_rabe_266',\n",
       " '665_sleuth_case2002',\n",
       " '666_rmftsa_ladata',\n",
       " '678_visualizing_environmental',\n",
       " '687_sleuth_ex1605',\n",
       " '690_visualizing_galaxy',\n",
       " '706_sleuth_case1202',\n",
       " '712_chscase_geyser1',\n",
       " 'banana',\n",
       " 'titanic']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "experiment_data_loader.experiment_data[\"000001\"][\"repetition_data\"][0].keys()\n",
    "\n",
    "data_dir = \"../experiments/experiment_000001/repetition_000000/data/\"\n",
    "\n",
    "with open(data_dir+\"dataset.dill\", 'rb') as data:\n",
    "    dataset = dill.load(data)\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72654d56acd94cff84444d11c6effa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExperimentDataPlotSelectionWidget(children=(HBox(children=(Label(value='Data Sources:', layout=Layout(min_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## experiment data selection plotter that takes as input the data loader to plot its loaded data\n",
    "experiment_data_plotter = eu.gui.jupyter.ExperimentDataPlotSelectionWidget(experiment_data_loader)\n",
    "display(experiment_data_plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Execution time\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m raw_summary_data \u001b[38;5;241m=\u001b[39m experiment_data_loader\u001b[38;5;241m.\u001b[39mexperiment_data[\u001b[43mnum_str\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepetition_data\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(raw_summary_data\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(raw_summary_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_str' is not defined"
     ]
    }
   ],
   "source": [
    "### Execution time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_experiment_data(experiment_num):\n",
    "    num_str = \"%06d\" % experiment_num\n",
    "    #repetition_str = \"%06d\" % repetition_num\n",
    "\n",
    "\n",
    "    base_dir = \"../experiments/experiment_\"+num_str+\"/\"\n",
    "    data_dir = \"../experiments/experiment_\"+num_str+\"/repetition_000000/data/\"\n",
    "\n",
    "    with open(data_dir+\"dataset.dill\", 'rb') as data:\n",
    "        datasets = dill.load(data)\n",
    "\n",
    "\n",
    "    means = {}\n",
    "    stds = {}\n",
    "\n",
    "    train_loss = {}\n",
    "    test_loss = {}\n",
    "    val_loss = {}\n",
    "\n",
    "    # Iterate over each entry in the given path\n",
    "    for repetition_entry in os.listdir(base_dir):\n",
    "        # Create full path\n",
    "        repetition_path = os.path.join(base_dir, repetition_entry)\n",
    "\n",
    "        if not os.path.isdir(repetition_path):\n",
    "            continue\n",
    "\n",
    "\n",
    "        for dataset_entry in os.listdir(repetition_path):\n",
    "            dataset_path = os.path.join(repetition_path, dataset_entry)\n",
    "            if os.path.isdir(dataset_path) and \"data\" in dataset_entry and dataset_entry != \"data\":\n",
    "                dataset_name = dataset_entry[4:]\n",
    "\n",
    "                if dataset_name not in means:\n",
    "                    means[dataset_name] = []\n",
    "                    stds[dataset_name] = []\n",
    "                    train_loss[dataset_name] = []\n",
    "                    test_loss[dataset_name] = []\n",
    "                    val_loss[dataset_name] = []\n",
    "\n",
    "                _rep_dataset_means = []\n",
    "                _rep_dataset_stds = []\n",
    "\n",
    "                _test_loss = None\n",
    "                _train_loss = None\n",
    "                _val_loss = None\n",
    "\n",
    "                for data_entry in os.listdir(dataset_path):\n",
    "                \n",
    "                    try:\n",
    "                        data_path = os.path.join(dataset_path, data_entry)\n",
    "\n",
    "                        if \"mean\" in data_entry and data_entry[0] != \".\":\n",
    "                            mean = np.load(data_path)\n",
    "                            _rep_dataset_means.append(mean)\n",
    "\n",
    "                        if \"std\" in data_entry and data_entry[0] != \".\":\n",
    "                            std = np.load(data_path)\n",
    "                            _rep_dataset_stds.append(std)\n",
    "\n",
    "                        if \"train_loss\" in data_entry and data_entry[0] != \".\":\n",
    "                            _train_loss = np.load(data_path)\n",
    "\n",
    "                        if \"test_loss\" in data_entry and data_entry[0] != \".\":\n",
    "                            _test_loss = np.load(data_path)\n",
    "\n",
    "                        if \"val_loss\" in data_entry and data_entry[0] != \".\":\n",
    "                            _val_loss = np.load(data_path)\n",
    "                    except:\n",
    "                        print(f\"Error at retrieving data for: {data_entry}\")\n",
    "\n",
    "                if len(_rep_dataset_means) > 0:\n",
    "                    _rep_dataset_means = np.stack(_rep_dataset_means)\n",
    "\n",
    "                if len(_rep_dataset_stds) > 0:\n",
    "                    _rep_dataset_stds = np.stack(_rep_dataset_stds)\n",
    "\n",
    "                means[dataset_name].append(_rep_dataset_means)\n",
    "                stds[dataset_name].append(_rep_dataset_stds)\n",
    "                train_loss[dataset_name].append(_train_loss)\n",
    "                test_loss[dataset_name].append(_test_loss)\n",
    "                val_loss[dataset_name].append(_val_loss)\n",
    "\n",
    "\n",
    "    for key,val in means.items():\n",
    "        try:\n",
    "            means[key] = np.stack(val).transpose((0,2,1))\n",
    "            #print(f\"loaded means {means[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "    for key,val in stds.items():\n",
    "        try:\n",
    "            stds[key] = np.stack(val).transpose((0,2,1))\n",
    "            #print(f\"loaded stds {stds[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "    for key,val in train_loss.items():\n",
    "        try:\n",
    "            train_loss[key] = np.stack(val).transpose((1,0))\n",
    "            #print(f\"loaded train {train_loss[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "    for key,val in test_loss.items():\n",
    "        try:\n",
    "            test_loss[key] = np.stack(val).transpose((1,0))\n",
    "            #print(f\"loaded test {test_loss[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\") \n",
    "\n",
    "    for key,val in val_loss.items():\n",
    "        try:\n",
    "            val_loss[key] = np.stack(val).transpose((1,0))\n",
    "            #print(f\"loaded val {val_loss[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "\n",
    "            \n",
    "    return means, stds, train_loss, test_loss, val_loss\n",
    "    \n",
    "means, stds, train_loss, test_loss, val_loss = load_experiment_data(15)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"1096_FacultySalaries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plotting\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = means[dataset_name][0]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardDeviation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### plot\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = stds[dataset_name][0]\n",
    "    \n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = test_loss[dataset_name]\n",
    "    \n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "\n",
    "\n",
    "data = np.expand_dims(data.mean(axis = 1), axis = 1)\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "    \n",
    "\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = val_loss[dataset_name]\n",
    "    \n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "\n",
    "\n",
    "data = np.expand_dims(data.mean(axis = 1), axis = 1)\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "    \n",
    "\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback \n",
    "\n",
    "max_method_num = 48\n",
    "\n",
    "min_test_loss = {}\n",
    "min_val_test_loss = {}\n",
    "\n",
    "for i in range(1,max_method_num):\n",
    "    means, stds, train_loss, test_loss, val_loss = load_experiment_data(i)    \n",
    "    for dataset in list(train_loss.keys()):\n",
    "        print(f\"Analyzing: {dataset} {i}\")\n",
    "        \n",
    "        try:\n",
    "            rep_min_test_loss = np.min(np.mean(test_loss[dataset],axis = 1),axis=0)\n",
    "            idx_min_val_loss = np.argmin(np.mean(val_loss[dataset],axis = 1),axis=0)\n",
    "            \n",
    "            if dataset not in min_test_loss:\n",
    "                min_test_loss[dataset] = {}\n",
    "                \n",
    "            if dataset not in min_val_test_loss:\n",
    "                min_val_test_loss[dataset] = {}\n",
    "\n",
    "            min_test_loss[dataset][i] = rep_min_test_loss\n",
    "            min_val_test_loss[dataset][i] = np.mean(test_loss[dataset],axis = 1)[idx_min_val_loss]\n",
    "            \n",
    "            print(np.mean(test_loss[dataset],axis = 1)[idx_min_val_loss])\n",
    "        except: \n",
    "            traceback.print_exc() \n",
    "\n",
    "### remove all inclompete datasets...\n",
    "to_delete = []\n",
    "for key, val in min_test_loss.items():\n",
    "    if len(val.keys()) < max_method_num - 1:\n",
    "        print(f\"For {key} not all datasets present {len(val.keys())}\")\n",
    "        to_delete.append(key)\n",
    "\n",
    "\n",
    "#for key in to_delete:\n",
    "#    del min_test_loss[key]\n",
    "#    del min_val_test_loss[key]\n",
    "        \n",
    "### Calculate with reference to specific method\n",
    "reference_method = 4\n",
    "\n",
    "# Calculate relative min test loss\n",
    "relative_min_test_loss = {}\n",
    "relative_min_val_test_loss = {}\n",
    "\n",
    "for dataset_name, dataset_vals in min_test_loss.items():\n",
    "    relative_min_test_loss[dataset_name] = {method: val / dataset_vals[reference_method] for method, val in dataset_vals.items()}\n",
    "\n",
    "for dataset_name, dataset_vals in min_val_test_loss.items():    \n",
    "    relative_min_val_test_loss[dataset_name] = {method: val / dataset_vals[reference_method] for method, val in dataset_vals.items()}    \n",
    "\n",
    "\n",
    "#full_relative_min_test_loss = {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "colors = [*colors,*colors,*colors,*colors]\n",
    "\n",
    "dataset_names = list(min_test_loss.keys())\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    # Extract methods and corresponding test losses for the current dataset\n",
    "    methods = list(relative_min_test_loss[dataset_name].keys())\n",
    "    test_losses = [relative_min_test_loss[dataset_name][method] for method in methods]\n",
    "\n",
    "    # Create a bar chart for the current dataset\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=methods,\n",
    "            y=test_losses,\n",
    "            name=dataset_name,\n",
    "            marker_color=colors[:len(methods)]  # Assign different colors to each bar\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    print(methods)\n",
    "    \n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "        title=f'Relative Min Test Loss by Method for {dataset_name}',\n",
    "        xaxis=dict(\n",
    "            title='Method',\n",
    "            #tickmode='array',\n",
    "            #tickvals=list(range(len(methods))),\n",
    "            #ticktext=methods\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Relative Min Test Loss'\n",
    "        ),\n",
    "        legend_title=dataset_name\n",
    "        # Additional customizations can be added here\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_names = list(min_val_test_loss.keys())\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    # Preparing data for bar chart\n",
    "    methods = list(relative_min_val_test_loss[dataset_name].keys())\n",
    "    test_losses = [relative_min_val_test_loss[dataset_name][method] for method in methods]\n",
    "\n",
    "\n",
    "    # Create a bar chart for the current dataset\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=methods,\n",
    "            y=test_losses,\n",
    "            name=dataset_name,\n",
    "            marker_color=colors[:len(methods)]  # Assign different colors to each bar\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "        title=f'Relative Min Test Loss by Method for {dataset_name}',\n",
    "        xaxis=dict(\n",
    "            title='Method',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Relative Min Test Loss'\n",
    "        ),\n",
    "        legend_title=dataset_name\n",
    "        # Additional customizations can be added here\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The mean over all datasets is not a good indicator!! (Prone to outliers) Every dataset has different properties and therefore different methods perform best.\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "dataset_names = list(min_val_test_loss.keys())\n",
    "\n",
    "summary_test_loss = {}\n",
    "\n",
    "\n",
    "for dataset_name, dataset_vals in relative_min_val_test_loss.items():\n",
    "    for method_name, method_val in dataset_vals.items():\n",
    "        if method_name not in summary_test_loss:\n",
    "            summary_test_loss[method_name] = []\n",
    "        \n",
    "        summary_test_loss[method_name].append(method_val)\n",
    "        \n",
    "for method_name, method_vals in summary_test_loss.items():\n",
    "    summary_test_loss[method_name] = np.mean(method_vals)\n",
    "\n",
    "\n",
    "# Adding bars for each dataset\n",
    "methods = list(summary_test_loss.keys())\n",
    "index = np.arange(len(methods))  # the label locations\n",
    "\n",
    "test_losses = [summary_test_loss[method] for method in methods]\n",
    "dataset_name = \"summary\"\n",
    "# Create a bar chart for the current dataset\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        x=methods,\n",
    "        y=test_losses,\n",
    "        name=dataset_name,\n",
    "        marker_color = colors[:len(methods)]  # Assign different colors to each bar\n",
    "    )\n",
    "])\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title=f'Relative Min Test Loss by Method for {dataset_name}',\n",
    "    xaxis=dict(\n",
    "        title='Method',\n",
    "        tickmode='array',\n",
    "        tickvals=list(range(len(methods))),\n",
    "        ticktext=methods\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Relative Min Test Loss'\n",
    "    ),\n",
    "    legend_title=dataset_name\n",
    "    # Additional customizations can be added here\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "dataset_names = list(relative_min_val_test_loss.keys())\n",
    "methods = list(set([method for dataset in relative_min_val_test_loss.values() for method in dataset.keys()]))\n",
    "\n",
    "# Prepare data for heatmap\n",
    "heatmap_data = []\n",
    "best_methods_indices = []\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    dataset_vals = []\n",
    "    best_loss = float('inf')\n",
    "    best_method_index = -1\n",
    "\n",
    "    for index, method in enumerate(methods):\n",
    "        loss = relative_min_val_test_loss[dataset].get(method, None)\n",
    "        dataset_vals.append(loss)\n",
    "\n",
    "        if loss is not None and loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_method_index = index\n",
    "    \n",
    "    heatmap_data.append(dataset_vals)\n",
    "    best_methods_indices.append(best_method_index)\n",
    "\n",
    "# Create the heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_data,\n",
    "    x=methods,\n",
    "    y=dataset_names,\n",
    "    colorscale='Turbo'\n",
    "))\n",
    "\n",
    "# Overlay with scatter plot to highlight the best methods\n",
    "for i, best_index in enumerate(best_methods_indices):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[methods[best_index]],\n",
    "        y=[dataset_names[i]],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='red',\n",
    "            size=10,\n",
    "            line=dict(\n",
    "                color='red',\n",
    "                width=2\n",
    "            )\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Relative Min Test Loss by Method and Dataset',\n",
    "    xaxis=dict(title='Method'),\n",
    "    yaxis=dict(title='Dataset'),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming 'relative_min_val_test_loss' and 'dataset_names' are defined as before\n",
    "dataset_names = list(relative_min_val_test_loss.keys())\n",
    "\n",
    "# Finding methods across all datasets\n",
    "methods = list(set([method for dataset_vals in relative_min_val_test_loss.values() for method in dataset_vals.keys()]))\n",
    "\n",
    "# Initialize x, y, z for 3D scatter plot locations and test losses for color scale\n",
    "x, y, z, test_losses = [], [], [], []\n",
    "\n",
    "for i, dataset in enumerate(dataset_names):\n",
    "    for j, method in enumerate(methods):\n",
    "        loss = relative_min_val_test_loss[dataset].get(method)\n",
    "        if loss is not None:\n",
    "            x.append(j)  # method index\n",
    "            y.append(i)  # dataset index\n",
    "            z.append(loss)  # test loss\n",
    "            test_losses.append(loss)\n",
    "\n",
    "# Create 3D scatter plot with a continuous color scale\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=test_losses,  # Assign color based on test loss\n",
    "        colorscale='Viridis',  # Choose a color scale\n",
    "        colorbar=dict(title='Test Loss'),\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='Method', tickvals=list(range(len(methods))), ticktext=methods),\n",
    "        yaxis=dict(title='Dataset', tickvals=list(range(len(dataset_names))), ticktext=dataset_names),\n",
    "        zaxis=dict(title='Relative Min Test Loss')\n",
    "    ),\n",
    "    title='3D Scatter Plot of Relative Min Test Loss by Method and Dataset'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
