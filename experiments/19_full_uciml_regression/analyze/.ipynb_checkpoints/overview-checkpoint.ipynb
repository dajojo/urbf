{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b08165983eb45d584e1e27ff48d67a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExperimentDataLoaderWidget(children=(Box(children=(Button(description='Update Descriptions', layout=Layout(hei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5802eafbfe4e8d8dca14c872b1bfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "# import the experiment utilities package\n",
    "import exputils as eu\n",
    "import numpy as np\n",
    "\n",
    "# create an experiment data loader, by default it will load data from '../experiments'\n",
    "experiment_data_loader = eu.gui.jupyter.ExperimentDataLoaderWidget()\n",
    "\n",
    "display(experiment_data_loader)\n",
    "experiment_data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Data Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/requests/__init__.py:43: DeprecationWarning:\n",
      "\n",
      "'urllib3[secure]' extra is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1027_ESL', '1028_SWD', '1029_LEV', '1030_ERA', '1096_FacultySalaries', '1193_BNG_lowbwt', '1196_BNG_pharynx', '1199_BNG_echoMonths', '1201_BNG_breastTumor', '1203_BNG_pwLinear', '1595_poker', '192_vineyard', '210_cloud', '215_2dplanes', '218_house_8L', '225_puma8NH', '228_elusage', '229_pwLinear', '230_machine_cpu', '344_mv', '485_analcatdata_vehicle', '519_vinnie', '522_pm10', '523_analcatdata_neavote', '529_pollen', '537_houses', '547_no2', '556_analcatdata_apnea2', '557_analcatdata_apnea1', '561_cpu', '564_fried', '579_fri_c0_250_5', '591_fri_c1_100_10', '593_fri_c1_1000_10', '594_fri_c2_100_5', '595_fri_c0_1000_10', '596_fri_c2_250_5', '597_fri_c2_500_5', '599_fri_c2_1000_5', '601_fri_c1_250_5', '602_fri_c3_250_10', '604_fri_c4_500_10', '606_fri_c2_1000_10', '608_fri_c3_1000_10', '609_fri_c0_1000_5', '611_fri_c3_100_5', '612_fri_c1_1000_5', '613_fri_c3_250_5', '615_fri_c4_250_10', '617_fri_c3_500_5', '621_fri_c0_100_10', '623_fri_c4_1000_10', '624_fri_c0_100_5', '627_fri_c2_500_10', '628_fri_c3_1000_5', '631_fri_c1_500_5', '634_fri_c2_100_10', '635_fri_c0_250_10', '641_fri_c1_500_10', '646_fri_c3_500_10', '647_fri_c1_250_10', '649_fri_c0_500_5', '654_fri_c0_500_10', '656_fri_c1_100_5', '657_fri_c2_250_10', '659_sleuth_ex1714', '663_rabe_266', '665_sleuth_case2002', '666_rmftsa_ladata', '678_visualizing_environmental', '687_sleuth_ex1605', '690_visualizing_galaxy', '706_sleuth_case1202', '712_chscase_geyser1', 'banana', 'titanic']\n",
      "(488, 4)\n",
      "(1000, 10)\n",
      "(1000, 4)\n",
      "(1000, 4)\n",
      "(50, 4)\n",
      "(31104, 9)\n",
      "(1000000, 10)\n",
      "(17496, 9)\n",
      "(116640, 9)\n",
      "(177147, 10)\n",
      "(1025010, 10)\n",
      "(52, 2)\n",
      "(108, 5)\n",
      "(40768, 10)\n",
      "(22784, 8)\n",
      "(8192, 8)\n",
      "(55, 2)\n",
      "(200, 10)\n",
      "(209, 6)\n",
      "(40768, 10)\n",
      "(48, 4)\n",
      "(380, 2)\n",
      "(500, 7)\n",
      "(100, 2)\n",
      "(3848, 4)\n",
      "(20640, 8)\n",
      "(500, 7)\n",
      "(475, 3)\n",
      "(475, 3)\n",
      "(209, 7)\n",
      "(40768, 10)\n",
      "(250, 5)\n",
      "(100, 10)\n",
      "(1000, 10)\n",
      "(100, 5)\n",
      "(1000, 10)\n",
      "(250, 5)\n",
      "(500, 5)\n",
      "(1000, 5)\n",
      "(250, 5)\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from pmlb import fetch_data\n",
    "\n",
    "experiment_data_loader.experiment_data[\"000001\"][\"repetition_data\"][0].keys()\n",
    "\n",
    "data_dir = \"../experiments/experiment_000001/repetition_000000/data/\"\n",
    "\n",
    "with open(data_dir+\"dataset.dill\", 'rb') as data:\n",
    "    dataset_names = dill.load(data)\n",
    "\n",
    "print(dataset_names)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    X,Y = fetch_data(dataset_name, return_X_y=True)\n",
    "    print(f\"{dataset_name}: x -> {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97157a927ae54bcdb0cc582daf6fcd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExperimentDataPlotSelectionWidget(children=(HBox(children=(Label(value='Data Sources:', layout=Layout(min_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## experiment data selection plotter that takes as input the data loader to plot its loaded data\n",
    "experiment_data_plotter = eu.gui.jupyter.ExperimentDataPlotSelectionWidget(experiment_data_loader)\n",
    "display(experiment_data_plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execution time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dill' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 127\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m means, stds, train_loss, test_loss, val_loss\n\u001b[0;32m--> 127\u001b[0m means, stds, train_loss, test_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mload_experiment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m   \n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mload_experiment_data\u001b[0;34m(experiment_num)\u001b[0m\n\u001b[1;32m     10\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../experiments/experiment_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mnum_str\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/repetition_000000/data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(data_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset.dill\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m---> 13\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdill\u001b[49m\u001b[38;5;241m.\u001b[39mload(data)\n\u001b[1;32m     16\u001b[0m means \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     17\u001b[0m stds \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dill' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dill\n",
    "\n",
    "def load_experiment_data(experiment_num):\n",
    "    num_str = \"%06d\" % experiment_num\n",
    "    #repetition_str = \"%06d\" % repetition_num\n",
    "\n",
    "\n",
    "    base_dir = \"../experiments/experiment_\"+num_str+\"/\"\n",
    "    data_dir = \"../experiments/experiment_\"+num_str+\"/repetition_000000/data/\"\n",
    "\n",
    "    with open(data_dir+\"dataset.dill\", 'rb') as data:\n",
    "        datasets = dill.load(data)\n",
    "\n",
    "\n",
    "    means = {}\n",
    "    stds = {}\n",
    "\n",
    "    train_loss = {}\n",
    "    test_loss = {}\n",
    "    val_loss = {}\n",
    "\n",
    "    # Iterate over each entry in the given path\n",
    "    for repetition_entry in os.listdir(base_dir):\n",
    "        # Create full path\n",
    "        repetition_path = os.path.join(base_dir, repetition_entry)\n",
    "\n",
    "        if not os.path.isdir(repetition_path):\n",
    "            continue\n",
    "\n",
    "\n",
    "        for dataset_entry in os.listdir(repetition_path):\n",
    "            dataset_path = os.path.join(repetition_path, dataset_entry)\n",
    "            if os.path.isdir(dataset_path) and \"data\" in dataset_entry and dataset_entry != \"data\":\n",
    "                dataset_name = dataset_entry[4:]\n",
    "\n",
    "                if dataset_name not in means:\n",
    "                    means[dataset_name] = []\n",
    "                    stds[dataset_name] = []\n",
    "                    train_loss[dataset_name] = []\n",
    "                    test_loss[dataset_name] = []\n",
    "                    val_loss[dataset_name] = []\n",
    "\n",
    "                _rep_dataset_means = []\n",
    "                _rep_dataset_stds = []\n",
    "\n",
    "                _test_loss = None\n",
    "                _train_loss = None\n",
    "                _val_loss = None\n",
    "\n",
    "                for data_entry in os.listdir(dataset_path):\n",
    "                \n",
    "                    try:\n",
    "                        data_path = os.path.join(dataset_path, data_entry)\n",
    "\n",
    "                        if \"mean\" in data_entry and data_entry[0] != \".\":\n",
    "                            mean = np.load(data_path)\n",
    "                            _rep_dataset_means.append(mean)\n",
    "\n",
    "                        if \"std\" in data_entry and data_entry[0] != \".\":\n",
    "                            std = np.load(data_path)\n",
    "                            _rep_dataset_stds.append(std)\n",
    "\n",
    "                        if \"train_loss\" in data_entry and data_entry[0] != \".\":\n",
    "                            _train_loss = np.load(data_path)\n",
    "\n",
    "                        if \"test_loss\" in data_entry and data_entry[0] != \".\":\n",
    "                            _test_loss = np.load(data_path)\n",
    "\n",
    "                        if \"val_loss\" in data_entry and data_entry[0] != \".\":\n",
    "                            _val_loss = np.load(data_path)\n",
    "                    except:\n",
    "                        print(f\"Error at retrieving data for: {data_entry}\")\n",
    "\n",
    "                if len(_rep_dataset_means) > 0:\n",
    "                    _rep_dataset_means = np.stack(_rep_dataset_means)\n",
    "\n",
    "                if len(_rep_dataset_stds) > 0:\n",
    "                    _rep_dataset_stds = np.stack(_rep_dataset_stds)\n",
    "\n",
    "                means[dataset_name].append(_rep_dataset_means)\n",
    "                stds[dataset_name].append(_rep_dataset_stds)\n",
    "                train_loss[dataset_name].append(_train_loss)\n",
    "                test_loss[dataset_name].append(_test_loss)\n",
    "                val_loss[dataset_name].append(_val_loss)\n",
    "\n",
    "\n",
    "    for key,val in means.items():\n",
    "        try:\n",
    "            means[key] = np.stack(val).transpose((0,2,1))\n",
    "            #print(f\"loaded means {means[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "    for key,val in stds.items():\n",
    "        try:\n",
    "            stds[key] = np.stack(val).transpose((0,2,1))\n",
    "            #print(f\"loaded stds {stds[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "    for key,val in train_loss.items():\n",
    "        try:\n",
    "            train_loss[key] = np.stack(val).transpose((1,0))\n",
    "            #print(f\"loaded train {train_loss[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "    for key,val in test_loss.items():\n",
    "        try:\n",
    "            test_loss[key] = np.stack(val).transpose((1,0))\n",
    "            #print(f\"loaded test {test_loss[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\") \n",
    "\n",
    "    for key,val in val_loss.items():\n",
    "        try:\n",
    "            val_loss[key] = np.stack(val).transpose((1,0))\n",
    "            #print(f\"loaded val {val_loss[key].shape}\")\n",
    "        except:\n",
    "            print(\"Not present\")\n",
    "\n",
    "\n",
    "            \n",
    "    return means, stds, train_loss, test_loss, val_loss\n",
    "    \n",
    "means, stds, train_loss, test_loss, val_loss = load_experiment_data(15)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"1096_FacultySalaries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plotting\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = means[dataset_name][0]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardDeviation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### plot\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = stds[dataset_name][0]\n",
    "    \n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = test_loss[dataset_name]\n",
    "    \n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "\n",
    "\n",
    "data = np.expand_dims(data.mean(axis = 1), axis = 1)\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "    \n",
    "\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "data = val_loss[dataset_name]\n",
    "    \n",
    "# Preparing data for plotting\n",
    "epochs = np.arange(1, data.shape[0])\n",
    "traces = []\n",
    "\n",
    "\n",
    "data = np.expand_dims(data.mean(axis = 1), axis = 1)\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    traces.append(go.Scatter(x=epochs, y=data[:, i], mode='lines', name=f'Value {i+1}'))\n",
    "    \n",
    "\n",
    "\n",
    "# Plotting with Plotly\n",
    "layout = go.Layout(title='Change of 16 Values over 500 Steps',\n",
    "                   xaxis=dict(title='Epoch'),\n",
    "                   yaxis=dict(title='Value'),\n",
    "                   template='plotly_dark')\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback \n",
    "\n",
    "max_method_num = 48\n",
    "\n",
    "min_test_loss = {}\n",
    "min_val_test_loss = {}\n",
    "\n",
    "for i in range(1,max_method_num):\n",
    "    means, stds, train_loss, test_loss, val_loss = load_experiment_data(i)    \n",
    "    for dataset in list(train_loss.keys()):\n",
    "        print(f\"Analyzing: {dataset} {i}\")\n",
    "        \n",
    "        try:\n",
    "            rep_min_test_loss = np.min(np.mean(test_loss[dataset],axis = 1),axis=0)\n",
    "            idx_min_val_loss = np.argmin(np.mean(val_loss[dataset],axis = 1),axis=0)\n",
    "            \n",
    "            if dataset not in min_test_loss:\n",
    "                min_test_loss[dataset] = {}\n",
    "                \n",
    "            if dataset not in min_val_test_loss:\n",
    "                min_val_test_loss[dataset] = {}\n",
    "\n",
    "            min_test_loss[dataset][i] = rep_min_test_loss\n",
    "            min_val_test_loss[dataset][i] = np.mean(test_loss[dataset],axis = 1)[idx_min_val_loss]\n",
    "            \n",
    "            print(np.mean(test_loss[dataset],axis = 1)[idx_min_val_loss])\n",
    "        except: \n",
    "            traceback.print_exc() \n",
    "\n",
    "### remove all inclompete datasets...\n",
    "to_delete = []\n",
    "for key, val in min_test_loss.items():\n",
    "    if len(val.keys()) < max_method_num - 1:\n",
    "        print(f\"For {key} not all datasets present {len(val.keys())}\")\n",
    "        to_delete.append(key)\n",
    "\n",
    "\n",
    "#for key in to_delete:\n",
    "#    del min_test_loss[key]\n",
    "#    del min_val_test_loss[key]\n",
    "        \n",
    "### Calculate with reference to specific method\n",
    "reference_method = 4\n",
    "\n",
    "# Calculate relative min test loss\n",
    "relative_min_test_loss = {}\n",
    "relative_min_val_test_loss = {}\n",
    "\n",
    "for dataset_name, dataset_vals in min_test_loss.items():\n",
    "    relative_min_test_loss[dataset_name] = {method: val / dataset_vals[reference_method] for method, val in dataset_vals.items()}\n",
    "\n",
    "for dataset_name, dataset_vals in min_val_test_loss.items():    \n",
    "    relative_min_val_test_loss[dataset_name] = {method: val / dataset_vals[reference_method] for method, val in dataset_vals.items()}    \n",
    "\n",
    "\n",
    "#full_relative_min_test_loss = {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "colors = [*colors,*colors,*colors,*colors]\n",
    "\n",
    "dataset_names = list(min_test_loss.keys())\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    # Extract methods and corresponding test losses for the current dataset\n",
    "    methods = list(relative_min_test_loss[dataset_name].keys())\n",
    "    test_losses = [relative_min_test_loss[dataset_name][method] for method in methods]\n",
    "\n",
    "    # Create a bar chart for the current dataset\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=methods,\n",
    "            y=test_losses,\n",
    "            name=dataset_name,\n",
    "            marker_color=colors[:len(methods)]  # Assign different colors to each bar\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    print(methods)\n",
    "    \n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "        title=f'Relative Min Test Loss by Method for {dataset_name}',\n",
    "        xaxis=dict(\n",
    "            title='Method',\n",
    "            #tickmode='array',\n",
    "            #tickvals=list(range(len(methods))),\n",
    "            #ticktext=methods\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Relative Min Test Loss'\n",
    "        ),\n",
    "        legend_title=dataset_name\n",
    "        # Additional customizations can be added here\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_names = list(min_val_test_loss.keys())\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    # Preparing data for bar chart\n",
    "    methods = list(relative_min_val_test_loss[dataset_name].keys())\n",
    "    test_losses = [relative_min_val_test_loss[dataset_name][method] for method in methods]\n",
    "\n",
    "\n",
    "    # Create a bar chart for the current dataset\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=methods,\n",
    "            y=test_losses,\n",
    "            name=dataset_name,\n",
    "            marker_color=colors[:len(methods)]  # Assign different colors to each bar\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "        title=f'Relative Min Test Loss by Method for {dataset_name}',\n",
    "        xaxis=dict(\n",
    "            title='Method',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Relative Min Test Loss'\n",
    "        ),\n",
    "        legend_title=dataset_name\n",
    "        # Additional customizations can be added here\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The mean over all datasets is not a good indicator!! (Prone to outliers) Every dataset has different properties and therefore different methods perform best.\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "dataset_names = list(min_val_test_loss.keys())\n",
    "\n",
    "summary_test_loss = {}\n",
    "\n",
    "\n",
    "for dataset_name, dataset_vals in relative_min_val_test_loss.items():\n",
    "    for method_name, method_val in dataset_vals.items():\n",
    "        if method_name not in summary_test_loss:\n",
    "            summary_test_loss[method_name] = []\n",
    "        \n",
    "        summary_test_loss[method_name].append(method_val)\n",
    "        \n",
    "for method_name, method_vals in summary_test_loss.items():\n",
    "    summary_test_loss[method_name] = np.mean(method_vals)\n",
    "\n",
    "\n",
    "# Adding bars for each dataset\n",
    "methods = list(summary_test_loss.keys())\n",
    "index = np.arange(len(methods))  # the label locations\n",
    "\n",
    "test_losses = [summary_test_loss[method] for method in methods]\n",
    "dataset_name = \"summary\"\n",
    "# Create a bar chart for the current dataset\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        x=methods,\n",
    "        y=test_losses,\n",
    "        name=dataset_name,\n",
    "        marker_color = colors[:len(methods)]  # Assign different colors to each bar\n",
    "    )\n",
    "])\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title=f'Relative Min Test Loss by Method for {dataset_name}',\n",
    "    xaxis=dict(\n",
    "        title='Method',\n",
    "        tickmode='array',\n",
    "        tickvals=list(range(len(methods))),\n",
    "        ticktext=methods\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Relative Min Test Loss'\n",
    "    ),\n",
    "    legend_title=dataset_name\n",
    "    # Additional customizations can be added here\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "dataset_names = list(relative_min_val_test_loss.keys())\n",
    "methods = list(set([method for dataset in relative_min_val_test_loss.values() for method in dataset.keys()]))\n",
    "\n",
    "# Prepare data for heatmap\n",
    "heatmap_data = []\n",
    "best_methods_indices = []\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    dataset_vals = []\n",
    "    best_loss = float('inf')\n",
    "    best_method_index = -1\n",
    "\n",
    "    for index, method in enumerate(methods):\n",
    "        loss = relative_min_val_test_loss[dataset].get(method, None)\n",
    "        dataset_vals.append(loss)\n",
    "\n",
    "        if loss is not None and loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_method_index = index\n",
    "    \n",
    "    heatmap_data.append(dataset_vals)\n",
    "    best_methods_indices.append(best_method_index)\n",
    "\n",
    "# Create the heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_data,\n",
    "    x=methods,\n",
    "    y=dataset_names,\n",
    "    colorscale='Turbo'\n",
    "))\n",
    "\n",
    "# Overlay with scatter plot to highlight the best methods\n",
    "for i, best_index in enumerate(best_methods_indices):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[methods[best_index]],\n",
    "        y=[dataset_names[i]],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='red',\n",
    "            size=10,\n",
    "            line=dict(\n",
    "                color='red',\n",
    "                width=2\n",
    "            )\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Relative Min Test Loss by Method and Dataset',\n",
    "    xaxis=dict(title='Method'),\n",
    "    yaxis=dict(title='Dataset'),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming 'relative_min_val_test_loss' and 'dataset_names' are defined as before\n",
    "dataset_names = list(relative_min_val_test_loss.keys())\n",
    "\n",
    "# Finding methods across all datasets\n",
    "methods = list(set([method for dataset_vals in relative_min_val_test_loss.values() for method in dataset_vals.keys()]))\n",
    "\n",
    "# Initialize x, y, z for 3D scatter plot locations and test losses for color scale\n",
    "x, y, z, test_losses = [], [], [], []\n",
    "\n",
    "for i, dataset in enumerate(dataset_names):\n",
    "    for j, method in enumerate(methods):\n",
    "        loss = relative_min_val_test_loss[dataset].get(method)\n",
    "        if loss is not None:\n",
    "            x.append(j)  # method index\n",
    "            y.append(i)  # dataset index\n",
    "            z.append(loss)  # test loss\n",
    "            test_losses.append(loss)\n",
    "\n",
    "# Create 3D scatter plot with a continuous color scale\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=test_losses,  # Assign color based on test loss\n",
    "        colorscale='Viridis',  # Choose a color scale\n",
    "        colorbar=dict(title='Test Loss'),\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='Method', tickvals=list(range(len(methods))), ticktext=methods),\n",
    "        yaxis=dict(title='Dataset', tickvals=list(range(len(dataset_names))), ticktext=dataset_names),\n",
    "        zaxis=dict(title='Relative Min Test Loss')\n",
    "    ),\n",
    "    title='3D Scatter Plot of Relative Min Test Loss by Method and Dataset'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
